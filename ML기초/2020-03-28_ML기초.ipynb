{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML기초.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENYso35hnbpA",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# ┗(•̀へ •́ )ﾉ Hyun's Machine Learning\n",
        "---\n",
        "자 Machine Learning을 공부해봅시다 (´∇｀)  \n",
        "## Authored by. Hyun\n",
        "![미니언즈!](https://post-phinf.pstatic.net/MjAxNzA3MTBfMjIg/MDAxNDk5NjcxOTY1NDQw.Kz07JXiZg6AT6Y4PAZY7ubUNAr7rbDinLwFGuS0OOxcg.WVhpo8yfybUh0qImMGNAo1ucSUPuNOvQyzlO_vKlAlkg.JPEG/%EC%98%81%EC%A7%84%EC%9C%845.jpg?type=w1200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFbtD4uKrv3W",
        "colab_type": "text"
      },
      "source": [
        "# ┗(•̀へ •́  )ﾉ **이것만 돌리면 다 돌아간다~~~**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRO8gtPDrySn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 기본\n",
        "# import numpy as np\n",
        "# from numpy.linalg import inv\n",
        "# from numpy.linalg import solve\n",
        "# import random\n",
        "\n",
        "# import pandas as pd\n",
        "# from pandas import Series, DataFrame\n",
        "# import pandas_profiling\n",
        "# import openpyxl\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import urllib\n",
        "# import matplotlib.dates as mdates\n",
        "# from matplotlib.dates import bytespdate2num\n",
        "# import matplotlib.ticker as ticker\n",
        "# from matplotlib import font_manager, rc\n",
        "# from matplotlib import style\n",
        "# import seaborn as sns\n",
        "\n",
        "# import time\n",
        "\n",
        "# import itertools\n",
        "# import re\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# # 시계열 데이터 처리\n",
        "# import calendar\n",
        "# import dateutil\n",
        "# from dateutil.parser import parse\n",
        "# import datetime\n",
        "\n",
        "# # Network 분석\n",
        "# import networkx as nx\n",
        "\n",
        "# # 지도시각화\n",
        "# import folium\n",
        "# from folium import plugins\n",
        "# import html\n",
        "# import json\n",
        "# import geopy\n",
        "# from geopy.geocoders import Nominatim\n",
        "# import os\n",
        "# import requests\n",
        "# import ipywidgets\n",
        "# from IPython.display import Image\n",
        "# from ipywidgets import interact\n",
        "\n",
        "# # Clustering\n",
        "# from sklearn.cluster import KMeans\n",
        "# from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "\n",
        "# # Factor analysis\n",
        "# from factor_analyzer import FactorAnalyzer\n",
        "\n",
        "# # Machine learning 용도\n",
        "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import r2_score\n",
        "#from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import PredefinedSplit\n",
        "# from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
        "# from sklearn.metrics import (roc_curve, auc, accuracy_score, roc_auc_score)\n",
        "# from sklearn.cluster import KMeans\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "# from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from sklearn.preprocessing import RobustScaler\n",
        "# from sklearn.datasets import make_blobs\n",
        "# import scipy.cluster.hierarchy as shc\n",
        "# from sklearn.cluster import AgglomerativeClustering\n",
        "# from xgboost import XGBRegressor\n",
        "# from catboost import CatBoostRegressor\n",
        "# from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
        "# from lightgbm import LGBMClassifier, LGBMRegressor\n",
        "# import lightgbm as lgb\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn import metrics\n",
        "\n",
        "# # Deep learning 용도\n",
        "# import torch\n",
        "# import torchvision.datasets as dsets\n",
        "# import torchvision.transforms as transforms\n",
        "# import random\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "\n",
        "# # Wordcloud\n",
        "# import konlpy\n",
        "# from konlpy.tag import Okt\n",
        "# import collections\n",
        "# from collections import Counter\n",
        "# from wordcloud import WordCloud, STOPWORDS as stopwords\n",
        "# from PIL import Image, ImageFilter\n",
        "# from wordcloud import ImageColorGenerator\n",
        "# import pickle\n",
        "\n",
        "# # 한글 사용하기\n",
        "# import matplotlib.font_manager as fm\n",
        "# from matplotlib import rc\n",
        "# font_name = fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
        "# rc('font', family=font_name)\n",
        "\n",
        "\n",
        "# # 크롤링\n",
        "#  from selenium import webdriver\n",
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# # 기타\n",
        "# from urllib.request import urlopen\n",
        "# from tqdm import tqdm\n",
        "# import time\n",
        "# from zeep import Client\n",
        "# from collections import namedtuple\n",
        "# import sqlite3\n",
        "\n",
        "# # 한 번에 matplotlib 그림 띄우기\n",
        "# %matplotlib inline    \n",
        "# %config InlineBackend.figure_format = 'retina'  #%matplotlib 뒤에 써주면 그래프를 더 높은 해상도로 보여줌\n",
        "\n",
        "# # 설정 관련\n",
        "# pd.set_option('display.max_columns', 200)\n",
        "# pd.set_option('display.max_rows', 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t88oG-qc-16q",
        "colab_type": "text"
      },
      "source": [
        "# 목차"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhANASX2-28p",
        "colab_type": "text"
      },
      "source": [
        "## 1. Machine Learning은 무엇일까???\n",
        "## 2. Machine Learning 관련 용어, 메소드 모음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO3dY4c56Gfw",
        "colab_type": "text"
      },
      "source": [
        "# 1. Machine learning은 무엇일까???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpmsSftm2QQq",
        "colab_type": "text"
      },
      "source": [
        "![](https://lh3.googleusercontent.com/HK5QOxzeXCF0CMWSTae2OkxXmxETt0lNlyTYrYhVTiNrGxFr33lLgCnjfGiSSQgVVmJhjlkx4gM8eo71BBV6HW_IAo1b-kzqJL4ZLcqeiUhXIYin0vjeTjxrJOQWRmNSve6TX-er2RQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2wWk6km_CWp",
        "colab_type": "text"
      },
      "source": [
        "## 도대체 머신러닝이 무엇이냐?\n",
        "- 머신러닝은 간단하게 말해서 기계가 기존의 데이터를 학습해서 사람보다 더 정확하게 새로운 데이터를 분류해주거나(classification) 구체적인 수치를 내놓는(regression) 것을 말함!!\n",
        "\n",
        "> 간단하게\n",
        "- 기존 데이터로 기계가 학습 \n",
        "- 새로운 데이터를 바탕으로 예측!\n",
        "\n",
        "좀 더 구체적으로 나누면\n",
        "\n",
        " > Step.1 데이터 전처리\n",
        "  1. EDA\n",
        "  2. FE\n",
        "\n",
        " > Step.2 Modeling\n",
        "  1. 데이터 나누기 (Train, Test)\n",
        "  2. 모델 학습시키기 (Train data)\n",
        "  3. 학습된 모델에 성능 평가하기 (Test data)\n",
        "  4. 성능을 높이기 위해 위 과정 반복\n",
        "\n",
        " > Step.3 Evaluation\n",
        "  1. 학습된 모델에 Test data 넣기\n",
        "  2. 결과 확인하기\n",
        "\n",
        "이렇게 나눌 수 있다.\n",
        "\n",
        "그림으로 살펴보면 요로로콤!\n",
        "\n",
        "![](https://github.com/hw79chopin/Python3_Code_book/blob/master/data/ML_Explanation.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0kBSwd8bBhS",
        "colab_type": "text"
      },
      "source": [
        "## Step 하나하나씩 살펴보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLCPuuuKbGjP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> Step.1 Data cleaning\n",
        "1. EDA\n",
        " - EDA는 Exploratory Data Analysis로 데이터를 전반적으로 훑어보면서 데이터의 특성을 파악하는 과정!\n",
        "2. FE\n",
        " - FE는 Feature Engineering으로 기계가 학습할 수 있게 데이터를 다듬어 특징(feature)를 생성해주는 과정이다.\n",
        " - FE는 모델 성능에 미치는 영향이 크기에 매우 중요하며 전문성과 시간, 비용이 많이 든다.\n",
        " - Pandas를 정말 많이 사용함 ㅋㅋ\n",
        "\n",
        "> Step.2 Modeling\n",
        "1. 데이터 나누기\n",
        " - 가지고 있는 데이터를 크게 Train, Test 데이터로 나눈다. \n",
        " - 자세한 설명은 뒤에 ```빈용 개념정리``` 부분 확인!\n",
        "2. 모델 학습시키기\n",
        " - Train data를 활용해서 모델을 학습시킨다.\n",
        " - 독립변수 X와 종속변수 Y의 상관관계를 기계가 학습하도록 하는 것!\n",
        "3. 성능 평가하기\n",
        " - Train data로 학습된 모델의 성능을 Test data (혹은 test data)로 평가해보기!\n",
        " - Evaluation 방법은 ```빈용 개념정리``` 부분 확인!\n",
        " - Train, Test, Validation data에 대한 자세한 설명은 뒤에 ```빈용 개념정리``` 부분 확인!\n",
        "4. 성능을 높이기 위해 위 과정 반복\n",
        " - 모델의 성능을 높이기 위해서 FE를 다시 해주거나, hyperparameter를 조정해주거나, grid search를 하거나, 여러 model로 돌려보는 등을 반복!\n",
        "\n",
        "> Step.3 Evaluation\n",
        " 1. 학습된 모델에 Test data 넣기\n",
        "  - 어느 정도 모델의 성능이 높아졌다고 생각하면 test data로 성능을 평가하기!\n",
        "  - 성능이 아직 낮으면 다시 Step.2로 돌아가기~^^\n",
        " 2. 결과 확인하기\n",
        "  - 성능이 괜찮게 나오면 자기 자신을 토닥여주며 만족하면 됨!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wRHFLFTcFBN",
        "colab_type": "text"
      },
      "source": [
        "## Machine Learning의 종류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IknJz98B6eFD",
        "colab_type": "text"
      },
      "source": [
        "![123123](https://wordstream-files-prod.s3.amazonaws.com/s3fs-public/styles/simple_image/public/images/machine-learning1.png?SnePeroHk5B9yZaLY7peFkULrfW8Gtaf&itok=yjEJbEKD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ7DZyJVcHzi",
        "colab_type": "text"
      },
      "source": [
        "- Machine Learning에는 크게 지도학습(Supervised Learning), 비지도학습(Unsupervised Learning)으로 나뉜다.\n",
        "\n",
        "> 지도학습\n",
        "- 답이 이미 있는 데이터를 기계가 학습한 뒤, 새로운 데이터가 들어왔을 때 답을 예측하는 방법\n",
        "- Regression, Classification이 이에 해당\n",
        "\n",
        "> 비지도학습\n",
        " - 답이 없는 데이터의 특징들을 기계가 스스로 학습한 뒤 이를 바탕으로 답을 내주는 방법\n",
        " - Clustering, Dimensionality Reduction이 이에 해당"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJWmUSDlAyOK",
        "colab_type": "text"
      },
      "source": [
        "# 2. Machine Learning 관련 용어, 메소드 모음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLx__wuPieBe",
        "colab_type": "text"
      },
      "source": [
        "## Machine learning 빈용 개념정리\n",
        "---\n",
        "\n",
        "### **순서**\n",
        "\n",
        "> Bagging vs Boosting\n",
        "\n",
        "> Bias와 Variance\n",
        "\n",
        "> Cost function, Loss function, Objecetive function\n",
        "\n",
        "> Cross Validation vs Hold-out Validation\n",
        "\n",
        "> Data 나누기 (Train data, Test data, Split data)\n",
        "\n",
        "> Evaluation (F1 score, accuracy, precision, ROC, AUC. MAE, MSE, MAPE)\n",
        "\n",
        "> Overfitting, Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AvQgkfqSKEC",
        "colab_type": "text"
      },
      "source": [
        "### Bagging vs Boosting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orswR1yswPMb",
        "colab_type": "text"
      },
      "source": [
        "> Boosting이란?  \n",
        "![123123](https://quantdare.com/wp-content/uploads/2016/04/bb3.png)\n",
        "- Bagging은 샘플을 여러 번 뽑아 각 모델을 학습시켜 결과를 집계(Aggregating) 하는 방법이다.\n",
        "- Boosting은 Bagging과 다르게 이전 모델의 오차를 고려하여 학습을 하는 Ensemble 모델이다!\n",
        "- 못 맞춘 데이터에 대해서만 순차적으로 학습시켜서 여러개의 모델을 학습함. 그래서 bagging에 비해서 상대적으로 속도가 많이 느리다. 그 전 모델의 학습이 끝나야 다음 모델학습이 가능하기 때문.\n",
        "\n",
        "> Bagging과 Boosting의 차이점  \n",
        "![123123](https://user-images.githubusercontent.com/31475037/59011343-5a586280-886f-11e9-86ab-3143ad265195.png)\n",
        "\n",
        "> Boosting 종류  \n",
        "![123123](https://image.slidesharecdn.com/mlstudyboostingv0-171128021615/95/boosting-bagging-vs-boosting-14-638.jpg?cb=1511939004)\n",
        "- 크게 Adaboost, GBM, Xgboost, Light GBM등이 있다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeHCabICQgtA",
        "colab_type": "text"
      },
      "source": [
        "### Bias와 Variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp5L3Mh63so4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "![bias](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F99CDCC33599AC28F075E3C)\n",
        "\n",
        "> Bias란?\n",
        " - Bias는 실제 값에서 멀어진 척도 \n",
        "\n",
        "> Variance란?\n",
        " - Variance는 예측된 값들이 서로 얼마나 멀리 떨어져 있는지에 대한 척도\n",
        "\n",
        "> Modeling의 목표\n",
        " - 왼쪽 위의 그림처럼 Bias도 낮고, Variance도 낮게, 즉 모두 정확하게 예측하는 것!\n",
        "\n",
        "> Bias, Variance and fitting\n",
        "- Overfitting 모델은 High Variace 모델이라고도 하는데(오른쪽 위), Train Data의 지엽적인 특성까지 반영되어 학습된 것은 잘 예측하지만, 학습되지 않은 데이터에 대해서는 예측력이 떨어지게 됨\n",
        "- Underfitting 모델은 High Bias 모델이라고 하는데(왼쪽 아래), 너무 적은 특성만을 반영하여, 예측의 범위가 좁고 정확도가 떨어지게 됨\n",
        "- 다시 말하면, Bias 에러가 높아지는 것은 많은 데이터를 고려하지 않아(=모델이 너무 단순해) 정확한 예측을 하지 못하는 경우를 말하고, Variance(분산) 에러는 노이즈까지 전부 학습해(=모델이 너무 복잡해) 약간의 input에도 예측 Y 값이 크게 흔들리는 것을 말함. \n",
        "- 이 두가지 에러가 **Trade-off** 관계에 있어서 이 둘을 모두 잡는 것은 불가능 한 딜레마가 생김\n",
        " ![graph](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F996DB433599AC34225B9BD)\n",
        "- Total Error가 최소인 지점을 찾기 위한 가장 효과적인 방법은 **Validation Set을 만드는 것**이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "konh6so3QisB",
        "colab_type": "text"
      },
      "source": [
        "### Cost function, Loss function, Objective function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_My2nQow3slr",
        "colab_type": "text"
      },
      "source": [
        "> Cost function\n",
        "- Cost function은 loss function의 합이다. \n",
        "- 즉 entire data set에서 loss funciton을 계산한 합이다.\n",
        "- 순간순간의 loss를 판단할 땐 loss function, 학습이 완료된 후에는 cost function!\n",
        "- A loss function is a part of a cost function which is a type of an objective function!!!\n",
        "\n",
        "> Loss function\n",
        "- Loss function은 data point에서의 오차. Single data set에서의 오차를 구하는 것\n",
        "순간순간의 loss를 판단할 땐 loss function, 학습이 완료된 후에는 cost function!\n",
        "- A loss function is a part of a cost function which is a type of an objective function!!!\n",
        "\n",
        "> Objective function\n",
        "- The most general term for any function that you optimize during training.\n",
        "- For example, a probability of generating training set in maximum likelihood approach is a well defined objective function, but it is not a loss function nor cost function (however you could define an equivalent cost function). For example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMGaKcfzRH7M",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validation vs Hold-out Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR1u65ZTRbAC",
        "colab_type": "text"
      },
      "source": [
        "- Validation Set을 만드는 대표적인 두 유형에는 Cross Validation과 에 대해 알아보겠습니다.\n",
        "\n",
        "> Cross Validation\n",
        "- Cross validation은 validation set을 뗄 만큼 data가 크지 않을 때 사용\n",
        "- Training Set을 여러 Subset으로 나누고 각 모델을 이 Subset의 조합으로 훈련시키고 나머지 부분으로 검증하는 방법이다.  \n",
        "![validation](https://t1.daumcdn.net/cfile/tistory/990DD2465B72F1491E)\n",
        "\n",
        "#### 메소드 모음\n",
        "- **KFold ( n_splits = , shuffle = True)**: KFold\n",
        "  - n_splits: 데이터를 몇 번 나눌꺼냐\n",
        "  - shuffle: 데이터를 나누기 전에 섞을건지\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_Hu6BgUi8aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross validation code\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "X = np.arange(16).reshape((8,-1)) ## 8개의 row, 2개의 column\n",
        "y = np.arange(8).reshape((-1,1))\n",
        "kf = KFold(n_splits=4) # 8개의 row를 각각 2줄짜리 4개의 set으로 분리합니다\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index] \n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# 각각의 iteration을 print합니다. 첫 줄의 의미는 2~7번째 row를 학습하고 0,1번째 row를 validation set으로 하여 검증한다는 것입니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8v7_Cxxi80h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kfold 예시1\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=10)\n",
        "lasso_regressor = Lasso()\n",
        "ridge_regressor = Ridge()\n",
        "\n",
        "lasso_mse = []\n",
        "ridge_mse = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    lasso_regressor.fit(X[train_index], y[train_index])\n",
        "    ridge_regressor.fit(X[train_index], y[train_index])\n",
        "    \n",
        "    lasso_mse.append(mean_squared_error(y[test_index], lasso_regressor.predict(X[test_index])))\n",
        "    ridge_mse.append(mean_squared_error(y[test_index], ridge_regressor.predict(X[test_index])))\n",
        "    \n",
        "sum(lasso_mse) / 10, sum(ridge_mse) / 10\n",
        "\n",
        "################################################################################################################\n",
        "\n",
        "# Kfold 예시2\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np \n",
        "\n",
        "lasso_regressor = Lasso(warm_start=False)\n",
        "ridge_regressor = Ridge()\n",
        "\n",
        "lasso_scores = cross_val_score(lasso_regressor, X, y, cv=10, \n",
        "                               scoring='neg_mean_squared_error')\n",
        "ridge_scores= cross_val_score(ridge_regressor, X, y, cv=10, \n",
        "                              scoring='neg_mean_squared_error')\n",
        "# cv: 몇 번 돌릴 것이냐. cross-validation, scoring: 점수를 측정하는 기준\n",
        "np.mean(lasso_scores), np.mean(ridge_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUu4aBOgRoI8",
        "colab_type": "text"
      },
      "source": [
        "> Hold-out Validation\n",
        "- 데이터를 무작위로 train set과 validation set, test set으로 구분한 뒤, train set과 validation set을 이용해 분석 모형을 구축하고, test set을 이용하여 분석 모형의 성능을 평가하는 방법  \n",
        "- step.1\n",
        " - Original Set을 무작위로 train set과 validation set, test set으로 구분!\n",
        "- step.2\n",
        "  - hyperparameter를 다르게 해 여러가지 세팅을 만들어본 뒤, 학습 알고리즘을 사용해 Train set에 모델을 학습시키뮤\n",
        "- step.3\n",
        "  - Validation Set로 모델의 성능을 평가해 가장 좋은 성능의 hyperparameter 세팅을 선택함\n",
        "- step.4\n",
        "  - Train Set은 보통 클수록 좋음. 그러므로 모델 선택 후에 Train Set와 Validation Set을 합쳐 더 큰 데이터셋으로 step.3에서 선택한 최선의 hyperparameter 세팅을 사용한 모델을 학습하기!\n",
        "- step.5 \n",
        "  - 이제 Test Set을 사용해 모델의 성능을 평가~\n",
        "- Cross Validation과의 차이점: Hold-out Validation에서 Test Set의 경우 모형에는 영향을 주지 않고, 모델의 성능 측정 만을 위해 사용된다는 점!\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHJVdAb03sh_",
        "colab_type": "text"
      },
      "source": [
        "### Data 나누기 \n",
        "(Train data, Test data, Validation data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtk3dxfIQpvk",
        "colab_type": "text"
      },
      "source": [
        "![datasets](https://t1.daumcdn.net/cfile/tistory/9951E5445AAE1BE025)\n",
        "> Validation Set이 왜 필요할까?\n",
        " - Validation Set을 통해 우리는 모델의 성능을 대략적으로 파악할 수 있음\n",
        " - Train Set의 일부를 떼어낸 후, 남은 부분을 학습한 뒤, 모델을 통해 떼어낸 부분에 대한 예측 진행!\n",
        " - 우리는 떼어낸 부분의 실제 값을 알고 있기 때문에 예측치와 비교하여 성능을 평가하는 여러 측정 공식을 통해 모델의 성능을 측정함\n",
        " -  그러니 Validation Set은 모의고사 문제인 셈이쥬.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_S9Z4by3seb",
        "colab_type": "text"
      },
      "source": [
        "### Model Evaluation (Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCiaUsuzVHE2",
        "colab_type": "text"
      },
      "source": [
        "[참조 사이트](https://frhyme.github.io/machine-learning/clf_%ED%8F%89%EA%B0%80%ED%95%98%EA%B8%B0/)  \n",
        "\n",
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/99DC064C5BE056CE10\" alt=\"Drawing\" style=\"width: 500px;\"/>  \n",
        "- True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)\n",
        "- False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)\n",
        "- False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)\n",
        "- True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AedwSafZY4tu"
      },
      "source": [
        "`A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBV7Nn9ZXaMo",
        "colab_type": "text"
      },
      "source": [
        "#### 정확도(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9Xu9a1LXUVb",
        "colab_type": "text"
      },
      "source": [
        "- 정확도(accuracy)란 전체 샘플 중 맞게 예측한 샘플 수의 비율\n",
        "- 높을수록 좋은 모형이고 일반적으로 학습에서 최적화 목적함수로 사용됨!!\n",
        "- 정확도(Accuracy)의 가장 큰 문제점은 **클래스의 분포가 같을 때만 이용 가능하다는 점**\n",
        "- 이러한 **단점을 보완**하는 지표가 정밀도(Precision)와 재현율(Recall), ROC 곡선과 AUC입니다.\n",
        "\n",
        "$$accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$$<br>\n",
        "``` python\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "accuracy_score(y_true, y_pred)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtJXnJNKXV30",
        "colab_type": "text"
      },
      "source": [
        "#### 정밀도(precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EPaMs0OXV8S",
        "colab_type": "text"
      },
      "source": [
        "- 정밀도(precision)란 positive 클래스에 속한다고 분류한 샘플 중 실제로 positive 클래스에 속하는 샘플 수의 비율\n",
        "- 높을수록 좋은 모형!!!\n",
        "\n",
        "$$precision=\\frac{TP}{TP+FP}$$\n",
        "\n",
        "``` python\n",
        "from sklearn.metrics import precision_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "precision_score(y_true, y_pred)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU_ReU8QXWEo",
        "colab_type": "text"
      },
      "source": [
        "#### 재현율(recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHaUHh1EXWIk",
        "colab_type": "text"
      },
      "source": [
        "- 재현율(recall)이란 실제 positive 클래스에 속한 표본 중에 positive 클래스에 속한다고 출력한 표본의 수의 비율\n",
        "- 높을수록 좋은 모형!!\n",
        "- TPR(true positive rate) 또는 민감도(sensitivity)라고도 합니다.\n",
        "\n",
        "$$recall=\\frac{TP}{TP+FN}$$\n",
        "\n",
        "``` python\n",
        "from sklearn.metrics import recall_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "recall_score(y_true, y_pred)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDZoiHjyXuTu",
        "colab_type": "text"
      },
      "source": [
        "#### F Score, F1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AZKUVmhXvhM",
        "colab_type": "text"
      },
      "source": [
        "- F Score는 precision과 recall의 **가중조화평균**\n",
        "- 베타($\\beta$)는 정밀도에 주어지는 가중치\n",
        "\n",
        "$$F_β=\\frac{(1+β^2)(precision*recall)}{β^2precision+recall}$$\n",
        " \n",
        "- 베타가 1인 경우가 F1 Score!\n",
        "$$F_1=\\frac{2⋅precision⋅recall}{precision+recall}$$\n",
        "\n",
        "``` python\n",
        "from sklearn.metrics import f1_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "f1_score(y_true, y_pred)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyf2bX3aaep",
        "colab_type": "text"
      },
      "source": [
        "#### Classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Afq16ZXvqL",
        "colab_type": "text"
      },
      "source": [
        "- Classification report는 sklearn 패키지의 metrics 패키지에서 precision, recall , F1 score를 구할 때 쓰는 메소드\n",
        "- Classification report는 각각의 클래스를 양성(positive) 클래스로 보았을 때의  precision, recall , F1 score를 각각 구하고 그 평균값으로 전체 모형의 성능을 평가함!!\n",
        "\n",
        "``` python\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=['class 0', 'class 1']))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEw5OQDyXvzl",
        "colab_type": "text"
      },
      "source": [
        "#### ROC, AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCTCVNqlbOvg",
        "colab_type": "text"
      },
      "source": [
        "> ROC, AUC\n",
        "- ROC이란 TPR과 FPR은 어떤 기준을 연속적으로 바꾸며 측정해야 하는데 이를 한눈에 볼 수 있게 한 것\n",
        "- AUC란 ROC 곡선 아래 부분의 면적이다. 1에 가까울수록 성능이 좋음!\n",
        "- ![ROC_curve](https://t1.daumcdn.net/cfile/tistory/262E8E3F544837AD27)<br>\n",
        "- 위 그림처럼 ROC 곡선은 TPR과 FPR이 둘다 [0,1]의 범위이며 (0,0)에서 (1,1)을 잇는 곡선이다. \n",
        "\n",
        "- TRP(True Positive Rate) = recall\n",
        "$$TPR=\\frac{TP}{TP+FN}$$<br>\n",
        "- FPR(False Positive Rate)\n",
        "$$FPR=\\frac{FP}{FP+TN}$$<br>\n",
        "- TPR과 FPR은 반비례 관계에 있음\n",
        "  - 예시) 3인지 아닌지 판단할 때, 조금만 3처럼 보여도 모두 3이라고 분류할 경우, 이 때의 TPR은 1에 가까워지지만 반대로 FPR은 매우 낮아진다. 반대로 조금만 비슷하지 않아도 모두 3이 아니라고 분류할 경우 TPR은 급격히 낮아져 0에 가까워지겠지만, FPR은 반대로 급격히 높아져 1에 가까워진다.(3이라고 분류 자체를 안하므로, 잘못 분류하는 경우가 없는 것). 이처럼 TPR과 FPR은 어떤 기준(언제 3이라고 예측할까?)을 연속적으로 바꾸며 측정해야 하는데 이를 한눈에 볼 수 있게 한 것이 바로 **ROC 곡선**입니다.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ZGnYi9Xv9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_true = np.array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
        "y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
        "roc_auc_score(y_true, y_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POW8Za7TX6oi",
        "colab_type": "text"
      },
      "source": [
        "시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gtchm7nX5Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, precision_recall_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def learn_and_eval_clf(x, y_true):\n",
        "    clf = LogisticRegression(random_state=42)\n",
        "    clf.fit(x, y_true)\n",
        "\n",
        "    y_pred = clf.predict(x)\n",
        "    print(\"accuracy_score: {}\".format( accuracy_score(y_true, y_pred)))\n",
        "    print(\"precision_score: {}\".format( precision_score(y_true, y_pred)))\n",
        "    #print(\"AUC: Area Under Curve: {}\".format(roc_auc_score(y_true, y_pred_proba[:, 1])))\n",
        "    #print(\"Classificcation Report: \\n{}\".format(classification_report(y_true, y_pred)))\n",
        "    #print(\"Confusition matrix: \\n{}\".format(confusion_matrix(y_true, y_pred)))\n",
        "\n",
        "    y_score = clf.decision_function(x)\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
        "\n",
        "    f, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n",
        "    f.set_size_inches((8, 4)) \n",
        "    axes[0].fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
        "    axes[0].set_title('Recall-Precision Curve')\n",
        "\n",
        "    axes[1].plot(fpr, tpr)\n",
        "    axes[1].plot([0, 1], [0, 1], linestyle='--')\n",
        "    axes[1].set_title('ROC curve')\n",
        "    #plt.save\n",
        "    return f\n",
        "\n",
        "## - 임의로 각각 평균이 0.0, 0.25인, 큰 차이가 나지 않는 샘플들을 뽑아서, 분류해본다. \n",
        "\n",
        "sample_size = 100\n",
        "x = np.vstack(\n",
        "    [np.random.normal(0, 1, sample_size*2).reshape(sample_size, 2), \n",
        "     np.random.normal(0.25, 1, sample_size*2).reshape(sample_size, 2), \n",
        "    ]\n",
        ")\n",
        "y_true = np.array([0 for i in range(0, sample_size)]+[1 for i in range(0, sample_size)])\n",
        "\n",
        "\n",
        "try1 = learn_and_eval_clf(x, y_true)\n",
        "\n",
        "### 임의로 각각 평균이 0.0, 2인, 큰 차이가 나지 않는 샘플들을 뽑아서, 분류해본다. \n",
        "\n",
        "sample_size = 100\n",
        "x = np.vstack(\n",
        "    [np.random.normal(0, 1, sample_size*2).reshape(sample_size, 2), \n",
        "     np.random.normal(2, 1, sample_size*2).reshape(sample_size, 2), \n",
        "    ]\n",
        ")\n",
        "y_true = np.array([0 for i in range(0, sample_size)]+[1 for i in range(0, sample_size)])\n",
        "try2 = learn_and_eval_clf(x, y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2Hj6aBncgJk",
        "colab_type": "text"
      },
      "source": [
        "### Model Evaluation (Regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJMPSJ60X7sC",
        "colab_type": "text"
      },
      "source": [
        "- Continuous한 값을 예측하는 Regression은 Accuracy 등의 분류 모델 평가 기준으로 평가하는 것이 부적절함!ㅡㅡ;;;\n",
        "- Classification은 맞게 분류했는지/아닌지만 평가하면 되지만 Regression은 정확하게 예측하지 못했더라도 정답과 비슷하게 맞추면 성능이 좋다고 평가해야하기 때문!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj9hOXCJX7wn",
        "colab_type": "text"
      },
      "source": [
        "#### MAE(Mean Absolute Error)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Kh5aGwX71E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mean_absolute_error(y_test, y_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IazaMePGX76R",
        "colab_type": "text"
      },
      "source": [
        "#### MSE(Mean Squared Error)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyzEFO5qX7-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(y_test, y_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD8jqOziX8DR",
        "colab_type": "text"
      },
      "source": [
        "#### MAPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0jrj1BGYH5Y",
        "colab_type": "text"
      },
      "source": [
        "- Scale Dependent Error의 단점을 보완하기 위한 방법이다.\n",
        "- 하지만 MAPE 역시 실제 예측 값이 1보다 작을 경우 분모가 작아져 무한대에 가까워질 수 있다는 단점이 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyhyWH_GYIbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import check_arrays\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    y_true, y_pred = check_arrays(y_true, y_pred)\n",
        "\n",
        "    #if _is_1d(y_true): \n",
        "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
        "\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8Gae7f3VB5Y",
        "colab_type": "text"
      },
      "source": [
        "### Overfitting, Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVAOq1gD3pv2",
        "colab_type": "text"
      },
      "source": [
        "![123123](https://mblogthumb-phinf.pstatic.net/MjAxODA3MzBfMjMy/MDAxNTMyODkwNjUxMjY4.H_ocFIRFaG8MWrBsv8BWrTCaAMGLMKZZUh_Rd1krRLog.HAZRdDtrQMvVGKiEWfGls8bm0EhTyRKf7XzoSY1Cibsg.JPEG.qbxlvnf11/maxresdefault.jpg?type=w800)\n",
        "\n",
        "> **과대적합(Overfitting)**이란?\n",
        " - 모델이 Train Dataset에 너무 잘 맞아서 일반성이 떨어지게 되는 문제\n",
        " - 즉 Train Dataset을 너무 과하게 학습해 학습되지 않은 데이터가 들어오면 분류하지 못하게 되는 것\n",
        " - 위 그림의 오른쪽 그림들이 과대적합의 예시\n",
        " - 보시다시피 Train Set을 거의 다 거치거나 분류해내며 굉장히 높은 성능을 보여주고 있지만, 새로운 변수에 대응하기 어려움\n",
        " - 그림의 가운데 모델이 적합한 모델이라고 할 수 있음!\n",
        "\n",
        "> **과소적합(Underfitting)**이란?\n",
        " - Overfitting과 반대 개념\n",
        " - 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못하는 것\n",
        " - 위 그림의 왼쪽 그림이 underfitting.\n",
        "<br>\n",
        "\n",
        "> Machine Learning에서 **Overfitting을 방지하는 방법**\n",
        " - 더 많은 데이터로 학습하기\n",
        " - Feature 개수 줄이기\n",
        " - 정규화(Regularization) 시키기 (e.g. L1, L2)  \n",
        "   ```용어 모음``` 확인\n",
        " - Early stopping: 어느 정도 loss가 줄어들지 않으면 학습 멈추기\n",
        "\n",
        "> Deep Learning에서 **Overfitting을 방지하는 방법**\n",
        " - Network size를 줄이기\n",
        " - Weight Decay\n",
        " - Dropout 해주기\n",
        " - Batch Normalization 해주기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEBuuhlkwIMu",
        "colab_type": "text"
      },
      "source": [
        "## Machine learning 용어 모음\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epC3tuHrwRmF",
        "colab_type": "text"
      },
      "source": [
        "`A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-agd97XdIq4",
        "colab_type": "text"
      },
      "source": [
        "> ### Accuracy (정확도)\n",
        "- 정확도(accuracy)란 전체 샘플 중 맞게 예측한 샘플 수의 비율\n",
        "- 높을수록 좋은 모형이고 일반적으로 학습에서 최적화 목적함수로 사용됨!!\n",
        "- 정확도(Accuracy)의 가장 큰 문제점은 **클래스의 분포가 같을 때만 이용 가능하다는 점**\n",
        "- 이러한 **단점을 보완**하는 지표가 정밀도(Precision)와 재현율(Recall), ROC 곡선과 AUC입니다.\n",
        "- $$accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$$<br>\n",
        "``` python\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "accuracy_score(y_true, y_pred)\n",
        "```\n",
        "\n",
        "> ### AUC\n",
        "- AUC란 ROC 곡선 아래 부분의 면적이다. 1에 가까울수록 성능이 좋음!\n",
        "\n",
        "> ### Batch size\n",
        "- Batch size: data를 나누는 것\n",
        "\n",
        "> ### Bagging\n",
        "- Bagging은 샘플을 여러 번 뽑아 각 모델을 학습시켜 결과를 집계(Aggregating) 하는 방법이다.\n",
        "\n",
        "> ### Bias\n",
        " - Bias는 실제 값에서 멀어진 척도 \n",
        "\n",
        "> ### bootstrapping\n",
        " - 통계학에서 가설을 test하거나 metric을 계산하지 전에 '중복을 허용한' random sampling을 적용하는 방법\n",
        " - Machine learning에서 bootstrapping이란 random sampling을 통해 train data를 늘리는 방법이다!\n",
        " - Overfitting을 줄이는 데 도움이 된다.\n",
        "\n",
        "> ### Cross validation\n",
        "- Cross validation은 validation set을 뗄 만큼 data가 크지 않을 때 사용\n",
        "- Training Set을 여러 Subset으로 나누고 각 모델을 이 Subset의 조합으로 훈련시키고 나머지 부분으로 검증하는 방법이다.\n",
        "\n",
        "> ### Cost function\n",
        "- Cost function은 loss function의 합이다. \n",
        "- 즉 entire data set에서 loss funciton을 계산한 합이다.\n",
        "- 순간순간의 loss를 판단할 땐 loss function, 학습이 완료된 후에는 cost function!\n",
        "- A loss function is a part of a cost function which is a type of an objective function!!!\n",
        "\n",
        "> ### Entropy\n",
        "- 불확실성에 대한 척도.\n",
        "- Entropy 함수  \n",
        "  $H_p(X) = \\mathbb{E}\\big[I(X)\\big] = \\mathbb{E} \\big[ \\log (\\frac{1}{p(X)}) \\big] = -\\sum_{i=1}^{n} p(x_i)\\log(p(x_i))$  \n",
        "  C는 범주의 갯수, q는 사건의 확률질량함수(probability mass function)\n",
        "- 예측이 어려울수록 정보의 양은 더 많아지고 엔트로피는 커진다.\n",
        "- 확률적으로 발생하는 사건에 대한 **정보량의 평균**. 놀람의 정도를 나타낸다고 볼 수 있다.\n",
        "\n",
        "> ### Epoch\n",
        "- one epoch: 모든 training example을 도는 것!\n",
        "\n",
        "> ### Gini Index\n",
        "- $G.I(A)=\\sum _{ i=1 }^{ d }{ { \\left( { R }_{ i }\\left( 1-\\sum _{ k=1 }^{ m }{ { p }_{ ik }^{ 2 } }  \\right)  \\right)  } }$\n",
        "- 정보의 순도를 측정할 때 사용하는 지표 중 하나\n",
        "\n",
        "> ### Gradient\n",
        "- Parameter들의 편미분계수, 기울기\n",
        "\n",
        "> ### Hold-out Validation\n",
        "- Validation set을 만드는 방법 중 하나\n",
        "- 데이터를 무작위로 train set과 validation set, test set으로 구분한 뒤, train set과 validation set을 이용해 분석 모형을 구축하고, test set을 이용하여 분석 모형의 성능을 평가하는 방법 \n",
        "- step.1\n",
        " - Original Set을 무작위로 train set과 validation set, test set으로 구분!\n",
        "- step.2\n",
        "  - hyperparameter를 다르게 해 여러가지 세팅을 만들어본 뒤, 학습 알고리즘을 사용해 Train set에 모델을 학습시키뮤\n",
        "- step.3\n",
        "  - Validation Set로 모델의 성능을 평가해 가장 좋은 성능의 hyperparameter 세팅을 선택함\n",
        "- step.4\n",
        "  - Train Set은 보통 클수록 좋음. 그러므로 모델 선택 후에 Train Set와 Validation Set을 합쳐 더 큰 데이터셋으로 step.3에서 선택한 최선의 hyperparameter 세팅을 사용한 모델을 학습하기!\n",
        "- step.5 \n",
        "  - 이제 Test Set을 사용해 모델의 성능을 평가~\n",
        "- Cross Validation과의 차이점: Hold-out Validation에서 Test Set의 경우 모형에는 영향을 주지 않고, 모델의 성능 측정 만을 위해 사용된다는 점! \n",
        "\n",
        "> ### Hyperparameter\n",
        "- 학습의 대상이 아니라 학습 이전에 정해놓은 변수\n",
        "- parameter는 학습의 대상이 되는 변수\n",
        "\n",
        "> ### Iteration\n",
        "- batch를 몇 번 학습에 사용했냐?\n",
        "- e.g. 1000개의 training set이 있고, batch size는 500이다. 그러므로 1 epoch 도는 동안 2 iteration이다.\n",
        "\n",
        "> ### Loss function  \n",
        "- Loss function은 data point에서의 오차. Single data set에서의 오차를 구하는 것\n",
        "순간순간의 loss를 판단할 땐 loss function, 학습이 완료된 후에는 cost function!\n",
        "- A loss function is a part of a cost function which is a type of an objective function!!!\n",
        "\n",
        "> ### MAE (Mean Absolute Error)\n",
        "```python\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mean_absolute_error(y_test, y_predict)\n",
        "```\n",
        "\n",
        "> ### MAPE (Mean Asolute Percentage Error)\n",
        "- Scale Dependent Error의 단점을 보완하기 위한 방법이다.\n",
        "- 하지만 MAPE 역시 실제 예측 값이 1보다 작을 경우 분모가 작아져 무한대에 가까워질 수 있다는 단점이 있다.\n",
        "``` python\n",
        "from sklearn.utils import check_arrays\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    y_true, y_pred = check_arrays(y_true, y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "```\n",
        "\n",
        "> ### MSE(Mean Squared Error)\n",
        "```python\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_test, y_predict)\n",
        "```\n",
        "\n",
        "> ### Objective function\n",
        "- The most general term for any function that you optimize during training.\n",
        "- For example, a probability of generating training set in maximum likelihood approach is a well defined objective function, but it is not a loss function nor cost function (however you could define an equivalent cost function). For example:\n",
        "\n",
        "> ### Overfitting\n",
        " - 모델이 Train Dataset에 너무 잘 맞아서 일반성이 떨어지게 되는 문제\n",
        " - 즉 Train Dataset을 너무 과하게 학습해 학습되지 않은 데이터가 들어오면 분류하지 못하게 되는 것\n",
        " - 위 그림의 오른쪽 그림들이 과대적합의 예시\n",
        " - 보시다시피 Train Set을 거의 다 거치거나 분류해내며 굉장히 높은 성능을 보여주고 있지만, 새로운 변수에 대응하기 어려움\n",
        " - 그림의 가운데 모델이 적합한 모델이라고 할 수 있음!\n",
        "\n",
        "> ### Precision (정밀도)\n",
        "- 정밀도(precision)란 positive 클래스에 속한다고 분류한 샘플 중 실제로 positive 클래스에 속하는 샘플 수의 비율\n",
        "- 높을수록 좋은 모형!!!\n",
        "$$precision=\\frac{TP}{TP+FP}$$\n",
        "``` python\n",
        "from sklearn.metrics import precision_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "precision_score(y_true, y_pred)\n",
        "```\n",
        "\n",
        "> ### Recall (재현율)\n",
        "- 재현율(recall)이란 실제 positive 클래스에 속한 표본 중에 positive 클래스에 속한다고 출력한 표본의 수의 비율\n",
        "- 높을수록 좋은 모형!!\n",
        "- TPR(true positive rate) 또는 민감도(sensitivity)라고도 합니다.\n",
        "$$recall=\\frac{TP}{TP+FN}$$\n",
        "``` python\n",
        "from sklearn.metrics import recall_score\n",
        "y_true = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
        "recall_score(y_true, y_pred)\n",
        "```\n",
        "\n",
        "> ### ROC\n",
        "- ROC이란 TPR과 FPR은 어떤 기준을 연속적으로 바꾸며 측정해야 하는데 이를 한눈에 볼 수 있게 한 것\n",
        "- ![ROC_curve](https://t1.daumcdn.net/cfile/tistory/262E8E3F544837AD27)<br>\n",
        "- 위 그림처럼 ROC 곡선은 TPR과 FPR이 둘다 [0,1]의 범위이며 (0,0)에서 (1,1)을 잇는 곡선이다. \n",
        "\n",
        "> ### Underfitting\n",
        " - Overfitting과 반대 개념\n",
        " - 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못하는 것\n",
        " - 위 그림의 왼쪽 그림이 underfitting.\n",
        "\n",
        "> ### Variance\n",
        " - Variance는 예측된 값들이 서로 얼마나 멀리 떨어져 있는지에 대한 척도"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygOPUNxI2uaa",
        "colab_type": "text"
      },
      "source": [
        "## Machine learning 관련 메소드 모음\n",
        "밑에 나오지 않은 기타 메소드들\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjjuHB0rwULR",
        "colab_type": "text"
      },
      "source": [
        "### 학습한 모델 저장하는 법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_W-Sdk6w8vO",
        "colab_type": "text"
      },
      "source": [
        "joblib 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlqZIRBCwWwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 저장할 때\n",
        "from sklearn.externals import joblib \n",
        "# 객체를 pickled binary file 형태로 저장한다 \n",
        "file_name = 'object_01.pkl' \n",
        "joblib.dump(obj, file_name) \n",
        "\n",
        "## 읽을 때\n",
        "from sklearn.externals import joblib \n",
        "# pickled binary file 형태로 저장된 객체를 로딩한다 \n",
        "file_name = 'object_01.pkl' \n",
        "obj = joblib.load(file_name) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_CciL_ew_OG",
        "colab_type": "text"
      },
      "source": [
        "pickle 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvMC4llKwA2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save Model Using Pickle\n",
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pickle\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "dataframe = pandas.read_csv(url, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "\n",
        "# Fit the model on training set\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# save the model to disk\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        " \n",
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, Y_test)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}