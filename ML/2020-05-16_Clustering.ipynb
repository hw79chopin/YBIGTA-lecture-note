{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-05-16 Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aFbtD4uKrv3W",
        "t88oG-qc-16q",
        "qO3dY4c56Gfw",
        "bJWmUSDlAyOK",
        "YLx__wuPieBe",
        "0AvQgkfqSKEC",
        "TeHCabICQgtA",
        "konh6so3QisB",
        "fMGaKcfzRH7M",
        "RHJVdAb03sh_",
        "r_S9Z4by3seb",
        "bxyf2bX3aaep",
        "vEw5OQDyXvzl",
        "P2Hj6aBncgJk",
        "N8Gae7f3VB5Y",
        "OEBuuhlkwIMu",
        "ZjjuHB0rwULR",
        "6PdHdvEww3aD",
        "XiDidYG-jsQy",
        "NXUWwMTJw9dq",
        "qvOxz3SYw9h8",
        "6zK5cpuckTJ3",
        "Y1XBnMuCw9l6",
        "Kyosm9OZw9qZ",
        "AFcp77hOw9uI",
        "G5PI_pRfw91l",
        "SwHw2i3oyho5",
        "kgZbjX5iw-AF",
        "iqB656qNygjH",
        "-EK-RY0opSNX",
        "tjMcvT33ymnI",
        "NY5w7x_6yqab",
        "OXWSQuGTyqlO",
        "CrvIqWElqhzM",
        "5Kt66CjqyzCz",
        "b_0h1642y2nI",
        "wGGUGYR9y4LI",
        "DvZ5Q-fky4TV",
        "3p0Lc8RFy4XJ",
        "Q4GE559ly4Zw",
        "5ynxIB0azGk2",
        "WuuADgPUzGz6"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENYso35hnbpA",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# ┗(•̀へ •́ )ﾉ Hyun's Machine Learning (Clustering)\n",
        "---\n",
        "자 Clustering을 공부해봅시다 (´∇｀)  \n",
        "## Authored by. Hyun\n",
        "![미니언즈!](https://post-phinf.pstatic.net/MjAxNzA3MTBfMjIg/MDAxNDk5NjcxOTY1NDQw.Kz07JXiZg6AT6Y4PAZY7ubUNAr7rbDinLwFGuS0OOxcg.WVhpo8yfybUh0qImMGNAo1ucSUPuNOvQyzlO_vKlAlkg.JPEG/%EC%98%81%EC%A7%84%EC%9C%845.jpg?type=w1200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t88oG-qc-16q",
        "colab_type": "text"
      },
      "source": [
        "# 목차"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhANASX2-28p",
        "colab_type": "text"
      },
      "source": [
        "## 1. 차차 정리해봅시다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_0h1642y2nI",
        "colab_type": "text"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZdmhewVhldP",
        "colab_type": "text"
      },
      "source": [
        "### Clustering이란....?\n",
        "\n",
        "- 대표적인 비지도학습. 집단이 주어지지 않은 데이터에 군집을 부여해주는 것\n",
        "- 군집 내의 분산을 최소화하고 군집 간의 분산을 최대한 유사한 개체로 묶어주는 것!\n",
        "- 방법은 크게 5개  \n",
        "`K-means clustering /Hierarchical clustering/ DBSCAN / Gaussian Muxture model (GMM) / KNN clustering`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGGUGYR9y4LI",
        "colab_type": "text"
      },
      "source": [
        "### K-means clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-0IYbgCg2-m",
        "colab_type": "text"
      },
      "source": [
        "- Centroid 방식을 활용하여 주어진 갯수에 맞게 군집을 나눠준다.\n",
        "- 각 cluster와의 유클리디안 거리 차이들을 구하고 그 값들의 분산을 최소화하는 방식\n",
        "- K-means의 한계\n",
        " 1. sub-optimal solution을 피하기 위해 여러번 시행해야 함\n",
        " 2. Cluster 갯수를 직접 지정해야 하며, Outlier에 취약하다 (유클리디안 거리여서)\n",
        " 3. Varying sizes, Different densities, Non-spherical shapes의 경우에 성능이 좋지 않다.\n",
        "\n",
        "> K-Means Algorithm \n",
        "1. 데이터 집합의 Objects 중에서 설정한 Cluster의 개수인 k개의 Centroid를 임으로 선택한다.  \n",
        "2. 집합 속의 모든 Objects와 앞서 선택한 Centroid와의 거리를 각각 구하고, 가장 가까운 Centroid가 속하는 Cluster에 Objects를 할당한다.  \n",
        "3. 같은 Cluster로 할당된 Objects들의 중심점을 찾고, 그 점을 새로운 Centroid로 설정한다.  \n",
        "4. Centroid의 변화가 없을 때까지 2-3 과정을 반복한다.\n",
        "\n",
        "> K-means++ Algorithm   \n",
        "1. 첫 initial point c1을 임의로 선택한다.  \n",
        "2. 이후의 initial point ct는 이전에 선택한 ct-1과의 거리인 d(ct-1, ct)가 큰 점이 높은 확률로 선택되도록 샘플링 확률 분포를 다음과 같이 조절하고, 이 분포에 따라 하나의 점을 선택한다.\n",
        "3. k 개의 initial points를 선택할 때까지 step 2를 반복한다.\n",
        "샘플링 확률 분포를 사용함에 따라 ct는 이전에 선택한 점 ct-1과 거리가 먼 점일 가능성이 높다. 한 가지 단점이 있다면, ct-1과 ct+1이 비슷할 수도 있다. (※Ball cut이라는 방법으로 해결 가능.)\n",
        "\n",
        "> 성능평가\n",
        " - K-means는 inertia 값으로 성능을 평가한다.\n",
        " - inertia는 K-Means Clustering으로 계산된 SSE 값\n",
        " - kmeans.inertia_ 을 통해 값을 구할 수 있으며, 작을수록 좋다.\n",
        " - kmeans.score(X) 를 통해서도 성능 파악이 가능한데, 이 값은 inertia의 음의 값이다. (일반적으로 클수록 좋다는 **\"greater is better\"** rule 때문에 사용된다.)\n",
        "\n",
        " > k개의 적절한 군집 수 찾는 방법\n",
        " 1. Rule of thumb </b>  \n",
        "가장 간단한 방법으로, 데이터의 수가 n이라고 할 때, 필요한 Cluster의 수는 다음과 같이 계산할 수 있다.  \n",
        "$$k ≈ \\sqrt{n / 2}$$\n",
        " 2. Elbow method <br>\n",
        "Cluster의 수를 순차적으로 늘려가면서 결과를 모니터링 한다. 만약 하나의 클러스터를 추가했을 때, 이전보다 훨씬 더 나은 결과를 나타내지 않는다면, 이전의 클러스터의 수를 구하고자 하는 클러스터의 수로 결정한다.  <br>\n",
        " <br>\n",
        " 3. Silhouette Method  \n",
        "  - Clustering의 품질을 정량적으로 계산해주는 방법이다. i번째 데이터 x(i)에 대한 실루엣 계수 s(i) 값은 아래의 식으로 정의 <br>\n",
        " ![silhouette formula](https://static.packt-cdn.com/products/9781788996402/graphics/739fcde8-e95d-4ab2-a2f2-f3fc804a8872.png) <br>\n",
        "  - a(i)는 Cluster 내부의 데이터 응집도(cohesion)를 나타내는 값으로, x(i)와 동일한 Cluster 내의 나머지 데이터들과의 평균거리이다.\n",
        "  - b(i)는 Cluster 간의 분리도(separation)를 나타내는 값으로, 데이터 x(i)와 가장 가까운 클러스터 내의 모든 데이터들과의 평균거리이다.\n",
        "  - 실루엣 계수 값은 1에 가까울 수록 최적화된 Clustering이다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StUbiWNhg-Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# K-means in image segmentation 예시\n",
        "img = plt.imread('./img/img_seg_1.jpg')\n",
        "\n",
        "X = img.reshape(-1,3)\n",
        "\n",
        "segmented_imgs = []\n",
        "n_colors = (20, 15, 10, 5, 3)\n",
        "for n_clusters in n_colors:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
        "    segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
        "    segmented_imgs.append(segmented_img.reshape(img.shape))\n",
        "    \n",
        "    \n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplots_adjust(wspace=0.05, hspace=0.1)\n",
        "\n",
        "plt.subplot(231)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original image\")\n",
        "plt.axis('off')\n",
        "\n",
        "for idx, n_clusters in enumerate(n_colors):\n",
        "    plt.subplot(232 + idx)\n",
        "    plt.imshow(segmented_imgs[idx])\n",
        "    plt.title(\"{} colors\".format(n_clusters))\n",
        "    plt.axis('off')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v86PdPAdg-kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Silhouette 분석 예시\n",
        "from __future__ import print_function\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_blobs(n_samples = 500, n_features = 2, centers = 4, cluster_std = 1.0,\n",
        "                  center_box = (-10.0, 10.0), shuffle = True, random_state = 1)\n",
        "\n",
        "range_n_clusters = [2, 3, 4, 5, 6]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    fig, (ax1, ax2) = plt. subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "    \n",
        "    ax1.set_xlim([-0.1, 1]) # 실루엣 계수 범위 지정\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters+1) * 10]) # 실루엣 클러스터 사이의 공간 만들기\n",
        "    \n",
        "    kmeans__ = KMeans(n_clusters = n_clusters, random_state = 10)\n",
        "    kmeans__labels = kmeans__.fit_predict(X)\n",
        "    \n",
        "    silhouette_avg = silhouette_score(X, kmeans__labels)\n",
        "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
        "    \n",
        "    sample_silhouette_values = silhouette_samples(X, kmeans__labels)\n",
        "    \n",
        "    y_lower = 10\n",
        "    \n",
        "    for i in range(n_clusters):\n",
        "        ith_cluster_silhouette_values = \\\n",
        "            sample_silhouette_values[kmeans__labels == i]\n",
        "            \n",
        "        ith_cluster_silhouette_values.sort()\n",
        "            \n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "            \n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i)) # silhouette plots 각각 label 붙이기\n",
        "\n",
        "        y_lower = y_upper + 10  # 다음 plot을 그리기위해 y_lower 새로 갱신\n",
        "        \n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "    \n",
        "    ax1.axvline(x = silhouette_avg, color = \"r\", linestyle=\"--\") # silhouette score 평균값 그리기\n",
        "    \n",
        "\n",
        "    # Cluster 보여주기 (2nd plot)\n",
        "    colors = cm.nipy_spectral(kmeans__labels.astype(float) / n_clusters)\n",
        "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
        "                c=colors, edgecolor='k')\n",
        "\n",
        "    kmeans__centers = kmeans__.cluster_centers_ # cluster labeling\n",
        "    ax2.scatter(kmeans__centers[:, 0], kmeans__centers[:, 1], marker='o',\n",
        "                c=\"white\", alpha=1, s=200, edgecolor='k') # centroid circle design\n",
        "\n",
        "    for i, c in enumerate(kmeans__centers):\n",
        "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
        "                    s=50, edgecolor='k')\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                  \"with n_clusters = %d\" % n_clusters),\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5R9OHf1g-3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Elbow 예시\n",
        "X, y = make_blobs(n_samples = 150, n_features = 2, centers = 3, cluster_std= 0.50, shuffle = True, random_state=0)\n",
        "\n",
        "def elbow(X):\n",
        "    sse = []\n",
        "    for i in range(1,11):\n",
        "        kmeans_elbow = KMeans(n_clusters = i, init = 'k-means++', random_state = 0)\n",
        "        kmeans_elbow.fit(X)\n",
        "        sse.append(kmeans_elbow.inertia_)\n",
        "        \n",
        "    plt.plot(range(1,11), sse, 'o-')\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('SSE(inertia)')\n",
        "    plt.xticks(np.arange(11))\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "elbow(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsQJZOzVg-8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kmeans 예시 (random, k-means ++)\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X, y = make_blobs(n_samples = 1000, centers = 4, cluster_std= 0.60, random_state=0)\n",
        "\n",
        "k = 6\n",
        "kmeans_random = KMeans(n_clusters = k, init = 'random', max_iter = 3)\n",
        "kmeans_plus = KMeans(n_clusters = k, init = 'k-means++', max_iter = 3)\n",
        "kmeans_random.fit(X)\n",
        "kmeans_plus.fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIc5Usg-g-_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 성능평가 예시\n",
        "print(\"inertia = {:5.2f}, score = {:5.2f}\".format(kmeans.inertia_, kmeans.score(X)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrGlJVzrg_Di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kmeans 예시1\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "X = np.array([[1, 2], [1, 4], [1, 0],\n",
        "               [10, 2], [10, 4], [10, 0]])\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)  # 2개의 cluster로 나눠라\n",
        "\n",
        "kmeans.labels_    # 각 데이터에 대한 클러스터 결과물\n",
        "# array([1, 1, 1, 0, 0, 0], dtype=int32)\n",
        "\n",
        "kmeans.predict([[0, 0], [12, 3]])\n",
        "# array([1, 0], dtype=int32)\n",
        "\n",
        "kmeans.cluster_centers_\n",
        "#array([[10.,  2.], [ 1.,  2.]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwYBaKX5hMGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kmeans 예시2\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "df = pd.DataFrame([\n",
        "        [2, 1],\n",
        "        [3, 2],\n",
        "        [3, 4],\n",
        "        [5, 5],\n",
        "        [7, 5],\n",
        "        [2, 5],\n",
        "        [8, 9],\n",
        "        [9, 10],\n",
        "        [6, 12]\n",
        "    ], columns=['hour', 'attendance'])\n",
        "\n",
        "model = KMeans(n_clusters=3)\n",
        "\n",
        "model.fit(df)\n",
        "\n",
        "y_predict = model.fit_predict(df)\n",
        "print(y_predict) \n",
        "#[0 0 0 2 2 0 1 1 1]\n",
        "\n",
        "df['cluster'] = y_predict\n",
        "print(df)\n",
        "'''\n",
        "   hour  attendance  cluster\n",
        "0     2           1        0\n",
        "1     3           2        0\n",
        "2     3           4        0\n",
        "3     5           5        2\n",
        "4     7           5        2\n",
        "5     2           5        0\n",
        "6     8           9        1\n",
        "7     9          10        1\n",
        "8     6          12        1\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAAHvcqYy4PZ",
        "colab_type": "text"
      },
      "source": [
        "### Hierarchical clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhk0YecehMLv",
        "colab_type": "text"
      },
      "source": [
        "- Connectivity method를 활용하여 Bottom-Up 방식으로 덴드로그램을 그려주고 거기서 주관에 의해서 적절한 군집 갯수를 찾는 방식. 큰 데이터에는 적용하기 힘들다.\n",
        "- [거리측정 방식](https://datascienceschool.net/view-notebook/094bcb7b86574711a2e8d81f26bce2f5/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCNTHwbxhMQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hierarchical clustering 예시1 (by.sklearn)\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
        "cluster.fit_predict(X)\n",
        "\n",
        "print(cluster.labels_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdj_3hPvhMTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hierarchical clustering 예시2 (실제 data로 응용하는 법)\n",
        "import scipy.cluster.hierarchy as shc\n",
        "data = customer_data.iloc[:, 3:5].values    # iloc 의미, 전체 row와 3~4번째 column의 값을 nparray 형식으로 반환\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title(\"Customer Dendograms\")\n",
        "dend = shc.dendrogram(shc.linkage(data, method='ward'))    # dendrogram에서 적정 군집 수를 파악하고\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')    # 그 군집 수를 적용시켜줌\n",
        "cluster.fit_predict(data)\n",
        "\n",
        "print(cluster.labels_)\n",
        "\n",
        "# scatter plot 그리기\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(data[:,0], data[:,1], c=cluster.labels_, cmap='rainbow')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ97q4hWhVf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hierarchical clustering 예시3\n",
        "linked = linkage(X, 'single')\n",
        "\n",
        "labelList = range(1, 11)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linked,\n",
        "            orientation='top',\n",
        "            labels=labelList,\n",
        "            distance_sort='descending',\n",
        "            show_leaf_counts=True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvZ5Q-fky4TV",
        "colab_type": "text"
      },
      "source": [
        "### DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Qq6IrzhXTe",
        "colab_type": "text"
      },
      "source": [
        "- Density-Based Spatial Clustering of Applications with Noise  \n",
        ": 밀도 기반의 클러스터링으로 점이 세밀하게 몰려 있는 것을 기준으로 Clustering을 하는 방법  \n",
        ": 어느 한 점을 기준으로 일정 반경 이내의 점들을 하나의 Cluster로 인식한다.\n",
        ": perdict() 기능이 없어서 예측을 위해서는 `KNeightborsClassifier`를 사용\n",
        "\n",
        "> DBSCAN Algorithm\n",
        "1. 한 점 P를 기준으로 ε(eps) 반경 내에 점이 지정한 개수(minPts) 이상이 있으면 해당 점 P를 Core Point라고 한다.\n",
        "2. 앞의 점 P를 Core Point로 하는 Cluster에 속하는 P'중에서 ε(eps) 반경 내에 점이 지정한 개수(minPts)보다 작으면 Border Point라고 한다.\n",
        "3. 이 외에 ε(eps) 반경을 만족하는 범위에 어떠한 점도 포함하지 않는 점 P\"을 Noise Point라고 한다.\n",
        "4. Core Point와 Border Point와 같이 ε(eps) 반경 내에 서로의 군집에 Points가 속하는 경우에 하나의 Cluster로 할당한다.\n",
        "\n",
        "> DBSCAN의 장점\n",
        "1. Cluster 개수를 지정하지 않아도 적절한 Cluster를 찾아준다.\n",
        "2. 불특정한 모양 분포를 Clustering 할 수 있다. (Density-based)\n",
        "3. Outlier를 Noise Point로 분류하여 Clustering 성능을 좋게 한다.\n",
        "\n",
        "> DBSCAN의 단점\n",
        "1. 입력하는 parameter 값에 따라, 다른 Clustering 결과를 보인다. \n",
        "2. 데이터 특성을 모를 경우에 hyper-parameter를 설정하기 어렵다. \n",
        "3. Computational Complexity가 Linearithmic Time( O(m log m) )을 따르는데, eps 값이 커짐에 따라 Quadratic Time( O(m2) )을 따르게 되어 복잡도가 증가한다.\n",
        "\n",
        "> DBSCAN in `python`\n",
        "- scikit-learn의 cluster 서브 패키지는 DBSCAN Clustering을 위한 DBSCAN Class를 제공한다.\n",
        "``` python\n",
        "DBSCAN (eps=0.5, min_samples=5, metric=’euclidean’, metric_params=None, algorithm=’auto’, leaf_size=30, p=None, n_jobs=None)\n",
        "```\n",
        "주요 parameter\n",
        " 1. eps: ε(epsilon)으로 samples 사이의 maximum distance로 Core Point를 지정하기 위한 최대 반경. \n",
        " 2. min_samples: Core Point를 기준으로 eps 반경 안에 속하는 samples의 개수.\n",
        "\n",
        "> 주요 메소드\n",
        " 1. .labels_ : sample이 지정된 Cluster를 확인. (labeling 이 '-1'로 된 것은 알고리즘에서 anomaly로 지정된 것이다.) \n",
        " 2. .core_sample_indices_ : core point로 지정된 것들의 index를 확인. (len()으로 core points 총 개수 확인 가능) \n",
        " 3. .components_ : core point의 좌표 확인."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohr5DwKohXdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DBSCAN 예시\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples = 1000, noise = .05, random_state = 0)\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps = 0.08, min_samples = 5)\n",
        "dbscan.fit(X)\n",
        "\n",
        "np.unique(dbscan.labels_)\n",
        "```\n",
        "# array([-1,  0,  1], dtype=int64)\n",
        "```\n",
        "\n",
        "dbscan.core_sample_indices_[:10]\n",
        "```\n",
        "# array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)\n",
        "```\n",
        "\n",
        "dbscan.components_[:10]\n",
        "```\n",
        "# array([[ 2.02100097,  0.49017924],\n",
        "        [ 1.6782009 , -0.20198687],\n",
        "        [-0.28224484,  0.85878484],\n",
        "        [-0.02143996,  0.17628146],\n",
        "        [ 0.50484202, -0.3910431 ],\n",
        "        [ 1.96953895,  0.36005521],\n",
        "        [ 0.95659588,  0.2536649 ],\n",
        "        [ 0.0948788 ,  0.98337847],\n",
        "        [-0.4416603 ,  0.87203428],\n",
        "        [ 0.70751638, -0.5126737 ]])\n",
        "````\n",
        "\n",
        "## Classifier 예시\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 50)\n",
        "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])\n",
        "\n",
        "# 새로운 데이터 샘플을 임의로 설정\n",
        "X_new = np.array([[-0.5,0], [0,0.5], [1, -0.1], [2,1]])\n",
        "knn.predict(X_new)\n",
        "\n",
        "knn.predict_proba(X_new)\n",
        "```\n",
        "# array([[0.2 , 0.8 ],\n",
        "        [1.  , 0.  ],\n",
        "        [0.18, 0.82],\n",
        "        [1.  , 0.  ]])\n",
        "```\n",
        "\n",
        "core_mask = np.zeros_like(dbscan.labels_, dtype = bool)\n",
        "core_mask[dbscan.core_sample_indices_] = True\n",
        "noise_mask = dbscan.labels_ == -1\n",
        "border_mask = ~(core_mask | noise_mask)\n",
        "\n",
        "cores = dbscan.components_\n",
        "noise = X[noise_mask]\n",
        "border = X[border_mask]\n",
        "\n",
        "plt.scatter(cores[:,0], cores[:,1], s = 10, c = dbscan.labels_[core_mask])\n",
        "plt.scatter(noise[:,0], noise[:,1], c = 'r', marker = 'x', s= 30)\n",
        "plt.scatter(border[:,0], border[:,1], c = 'b', marker = '*', s = 30)\n",
        "\n",
        "plt.title(\"eps = 0.08, min_samples = 5\")\n",
        "\n",
        "# 새로 생성한 데이터를 추가\n",
        "plt.scatter(X_new[:,0], X_new[:,1], c= \"k\", marker = \"+\", s = 400, zorder = 999)\n",
        "\n",
        "y_dist, y_pred_idx = knn.kneighbors(X_new, n_neighbors=1)\n",
        "y_pred = dbscan.labels_[dbscan.core_sample_indices_][y_pred_idx]\n",
        "y_pred[y_dist > 0.2] = -1\n",
        "y_pred.ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uM2bgz0hbD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DBSCAN을 적용한 scatter plot\n",
        "core_mask = np.zeros_like(dbscan.labels_, dtype = bool)\n",
        "core_mask[dbscan.core_sample_indices_] = True\n",
        "noise_mask = dbscan.labels_ == -1\n",
        "border_mask = ~(core_mask | noise_mask)\n",
        "\n",
        "cores = dbscan.components_\n",
        "noise = X[noise_mask]\n",
        "border = X[border_mask]\n",
        "\n",
        "plt.scatter(cores[:,0], cores[:,1], s = 10, c = dbscan.labels_[core_mask])\n",
        "plt.scatter(noise[:,0], noise[:,1], c = 'r', marker = 'x', s= 30)\n",
        "plt.scatter(border[:,0], border[:,1], c = 'b', marker = '*', s = 30)\n",
        "\n",
        "plt.title(\"eps = 0.08, min_samples = 5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p0Lc8RFy4XJ",
        "colab_type": "text"
      },
      "source": [
        "### Gaussian Mixture model (GMM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlQ8kqj4hchX",
        "colab_type": "text"
      },
      "source": [
        "- Mixture Model이란, 전체 분포에서 하위 분포가 존재한다고 가정하는 모델이다.\n",
        "- 데이터가 모수를 가지는 여러 개의 분포로부터 합쳐진 형태라는 것이다.\n",
        "- 즉, Gaussian Mixture Model은 합쳐진 여러 개의 분포가 Gaussian Distribution의 형태인 것을 말한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfrtHrMahclu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GMM 예시\n",
        "# 분포 만들어주기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "dist1 = np.random.normal(-0.5, 0.2, 2000)\n",
        "dist2 = np.random.normal(-0.1, 0.07, 5000)\n",
        "dist3 = np.random.normal(0.2, 0.13, 10000)\n",
        "\n",
        "df1 = pd.DataFrame(dist1)\n",
        "df2 = pd.DataFrame(dist2)\n",
        "df3 = pd.DataFrame(dist3)\n",
        "df_merged = pd.concat([df1, df2, df3], ignore_index = True)\n",
        "\n",
        "df_merged_weights = np.ones_like(df_merged.values)\n",
        "\n",
        "plt.hist(df_merged.values, bins = 80, weights = df_merged_weights, color = 'tomato')\n",
        "\n",
        "plt.xlim(-1.3, 1.0)\n",
        "plt.ylabel('counts')\n",
        "plt.legend(['Merged Distribution'], loc = \"upper left\")\n",
        "plt.show()\n",
        "\n",
        "# GMM 쓰기\n",
        "from sklearn.mixture import GaussianMixture\n",
        "gmm = GaussianMixture(n_components = 3, n_init = 10)\n",
        "gmm.fit(df_merged)\n",
        "\n",
        "gmm.weights_\n",
        "\n",
        "gmm.means_\n",
        "\n",
        "gmm.covariances_\n",
        "\n",
        "gmm.converged_\n",
        "\n",
        "gmm.n_iter_\n",
        "\n",
        "gmm.predict(df_merged)\n",
        "\n",
        "# GMM 적용 후 결과 plot으로 나타내기\n",
        "import scipy.stats as stats\n",
        "\n",
        "weights = gmm.weights_\n",
        "means = gmm.means_\n",
        "covars = gmm.covariances_\n",
        "\n",
        "# df_merged를 dataframe에서 array로 변환\n",
        "arr_merged = df_merged.values.flatten()\n",
        "\n",
        "# 데이터 범위 및 개수\n",
        "xx = np.linspace(min(arr_merged),max(arr_merged),17000)\n",
        "\n",
        "pdf_1 = stats.norm(loc = means[0], scale = np.sqrt(covars[0]))\n",
        "pdf_2 = stats.norm(loc = means[1], scale = np.sqrt(covars[1]))\n",
        "pdf_3 = stats.norm(loc = means[2], scale = np.sqrt(covars[2]))\n",
        "\n",
        "n, bins, patches = plt.hist(df_merged.values, bins = 50, normed=True, facecolor='tomato', alpha = .4)\n",
        "plt.plot(xx,weights[0]*pdf_1.pdf(xx)[0], c='green')\n",
        "plt.plot(xx,weights[1]*pdf_2.pdf(xx)[0], c='royalblue')\n",
        "plt.plot(xx,weights[2]*pdf_3.pdf(xx)[0], c='orange')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4GE559ly4Zw",
        "colab_type": "text"
      },
      "source": [
        "### KNN clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf8mqYXLhfeo",
        "colab_type": "text"
      },
      "source": [
        "- 패턴 인식에서 분류나 회귀에 사용되는 비모수 방식이다. \n",
        "- 데이터의 지역 구조에 민감하다. 쉽게 구현이 되나 계산량이 많다.\n",
        "- 매우 일관성 있는 결과를 도출해낸다."
      ]
    }
  ]
}